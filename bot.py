import os
import json
import logging
import gspread
from oauth2client.service_account import ServiceAccountCredentials
import google.generativeai as genai
from dotenv import load_dotenv
from telegram import Update
from telegram.ext import (
    Application,
    CommandHandler,
    MessageHandler,
    filters,
    ContextTypes,
)

# --- CONFIGURA√á√ïES E INICIALIZA√á√ÉO (continua igual) ---
load_dotenv()
logging.basicConfig(
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s", level=logging.INFO
)
logger = logging.getLogger(__name__)

try:
    GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")
    genai.configure(api_key=GOOGLE_API_KEY)
    logger.info("API do Google AI (Gemini) configurada.")
except Exception as e:
    logger.error(f"Erro fatal ao configurar a API do Google: {e}")
    exit()

# --- NOVA ESTRUTURA PARA GERIR CONVERSAS ---

# Um dicion√°rio para guardar as conversas ativas de cada usu√°rio
# Chave: user_id, Valor: objeto de chat do Gemini
active_chats = {}

# O c√©rebro do nosso bot: a instru√ß√£o mestra que define seu comportamento
# Esta √© a parte mais importante da nova l√≥gica!
SYSTEM_PROMPT = """
Voc√™ √© um assistente de vendas virtual, seu nome √© LeadBot. Voc√™ √© amig√°vel, profissional e muito eficiente.
Sua miss√£o √© conversar com um potencial cliente para entender suas necessidades e coletar as seguintes informa√ß√µes:
1. Nome Completo
2. Endere√ßo de E-mail
3. N√∫mero de Telefone (WhatsApp)
4. √Årea de Interesse Principal (o servi√ßo que mais lhe chama a aten√ß√£o)

REGRAS IMPORTANTES:
- Fa√ßa APENAS UMA pergunta de cada vez.
- Seja natural e conversacional, n√£o pare√ßa um rob√¥ preenchendo um formul√°rio.
- Inicie a conversa se apresentando e pedindo o nome do usu√°rio.
- Ap√≥s coletar uma informa√ß√£o, confirme-a de forma sutil e pe√ßa a pr√≥xima.
- Quando voc√™ tiver coletado com sucesso TODAS as 4 informa√ß√µes (Nome, Email, Telefone e Interesse), finalize a sua resposta com a frase exata e sem formata√ß√£o adicional: [CONVERSA_FINALIZADA]
- N√£o use esta frase em nenhuma outra circunst√¢ncia.
"""

# As fun√ß√µes de salvar na planilha e classificar o lead continuam as mesmas
# ... (Copie aqui as suas fun√ß√µes `classify_lead_with_gemini` e `save_lead_to_sheet` da vers√£o anterior) ...
async def classify_lead_with_gemini(lead_data: dict) -> str:
    logger.info("Enviando dados para o Gemini para classifica√ß√£o...")
    try:
        model = genai.GenerativeModel('gemini-1.5-pro-latest')
        prompt = f"""
        Voc√™ √© um analista de vendas s√™nior. Analise os dados do lead abaixo e classifique seu potencial.
        Dados: {json.dumps(lead_data)}
        Use estritamente uma das seguintes classifica√ß√µes: "Lead Quente", "Lead Morno", "Lead Frio".
        Responda APENAS com a classifica√ß√£o.
        """
        response = await model.generate_content_async(prompt)
        classification = response.text.strip()
        logger.info(f"Classifica√ß√£o recebida do Gemini: '{classification}'")
        return classification
    except Exception as e:
        logger.error(f"Ocorreu um erro ao chamar a API do Gemini para classifica√ß√£o: {e}")
        return "Erro na Classifica√ß√£o"

async def save_lead_to_sheet(lead_data: dict):
    """Salva os dados de um lead em uma Planilha Google, lendo as credenciais de forma segura."""
    logger.info("Salvando lead na Planilha Google...")
    try:
        scope = ["https://spreadsheets.google.com/feeds", 'https://www.googleapis.com/auth/spreadsheets',
                 "https://www.googleapis.com/auth/drive.file", "https://www.googleapis.com/auth/drive"]

        creds_json_str = os.getenv("GDRIVE_CREDENTIALS")

        if creds_json_str:
            # Se estiver na nuvem (Render), l√™ as credenciais da vari√°vel de ambiente
            logger.info("Usando credenciais da vari√°vel de ambiente.")
            creds_dict = json.loads(creds_json_str)
            creds = ServiceAccountCredentials.from_json_keyfile_dict(creds_dict, scope)
        else:
            # Se estiver rodando localmente, usa o ficheiro credentials.json
            logger.info("Usando ficheiro local credentials.json.")
            creds = ServiceAccountCredentials.from_json_keyfile_name("credentials.json", scope)

        client = gspread.authorize(creds)
        sheet = client.open("Leads do Bot Telegram").sheet1
        data_row = [
            lead_data.get('Nome', ''),
            lead_data.get('Email', ''),
            lead_data.get('Telefone', ''),
            lead_data.get('Interesse', ''),
            lead_data.get('Classifica√ß√£o', ''),
            logging.Formatter().formatTime(logging.makeLogRecord({}))[:19]
        ]
        sheet.append_row(data_row)
        logger.info("Lead salvo com sucesso!")

    except Exception as e:
        logger.error(f"Erro ao salvar na Planilha Google: {e}")

# --- NOVAS FUN√á√ïES PRINCIPAIS DO BOT ---

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Inicia uma nova conversa ou reinicia uma existente."""
    user_id = update.message.from_user.id
    user_name = update.message.from_user.first_name
    
    # Se o usu√°rio j√° tiver uma conversa ativa, ela √© reiniciada.
    active_chats[user_id] = None 
    
    await update.message.reply_text(f"Ol√°, {user_name}! üëã Eu sou o LeadBot, seu assistente de vendas virtual. Vamos come√ßar?")
    await update.message.reply_text("Para iniciarmos, por favor, me diga seu nome completo.")


async def handle_conversation(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Gere toda a conversa usando a IA do Gemini."""
    user_id = update.message.from_user.id
    user_message = update.message.text

    # Verifica se existe uma conversa ativa para este usu√°rio
    if user_id not in active_chats or active_chats[user_id] is None:
        # Se n√£o houver, cria uma nova sess√£o de chat com o Gemini
        model = genai.GenerativeModel('gemini-1.5-pro-latest')
        # Inicia o chat e guarda na mem√≥ria (active_chats)
        active_chats[user_id] = model.start_chat(history=[
            {'role': 'user', 'parts': [SYSTEM_PROMPT]},
            {'role': 'model', 'parts': ["Ol√°! Eu sou o LeadBot, seu assistente de vendas virtual. Para come√ßarmos, qual √© o seu nome completo?"]}
        ])

    try:
        # Envia a mensagem do usu√°rio para a sess√£o de chat do Gemini
        chat_session = active_chats[user_id]
        response = await chat_session.send_message_async(user_message)
        ai_response_text = response.text

        # Verifica se a IA sinalizou o fim da coleta de dados
        if "[CONVERSA_FINALIZADA]" in ai_response_text:
            # Remove a frase de sinaliza√ß√£o da mensagem final
            final_message_to_user = ai_response_text.replace("[CONVERSA_FINALIZADA]", "").strip()
            await update.message.reply_text(final_message_to_user)
            await update.message.reply_text("Obrigado! S√≥ um momento enquanto processo e guardo suas informa√ß√µes.")
            
            logger.info(f"Conversa finalizada para o usu√°rio {user_id}. Extraindo dados...")

            # CRIA UMA NOVA CHAMADA √Ä IA PARA EXTRAIR OS DADOS DE FORMA ESTRUTURADA
            model_extractor = genai.GenerativeModel('gemini-1.5-pro-latest')
            extraction_prompt = f"""
            Analise o seguinte hist√≥rico de conversa e extraia as informa√ß√µes de Nome, Email, Telefone e Interesse do usu√°rio.
            Responda APENAS com um objeto JSON v√°lido. Se uma informa√ß√£o n√£o for encontrada, use o valor "N√£o informado".
            Exemplo de resposta: {{"Nome": "Jo√£o Silva", "Email": "joao.silva@email.com", "Telefone": "11999998888", "Interesse": "Integra√ß√£o com IA"}}

            Hist√≥rico da Conversa:
            {chat_session.history}
            """
            
            extraction_response = await model_extractor.generate_content_async(extraction_prompt)
            # Limpa a resposta para garantir que √© um JSON v√°lido
            lead_json_str = extraction_response.text.strip().replace("```json", "").replace("```", "")
            
            try:
                lead_data = json.loads(lead_json_str)
                logger.info(f"Dados extra√≠dos: {lead_data}")

                # Usa as fun√ß√µes que j√° t√≠nhamos para classificar e salvar
                classification = await classify_lead_with_gemini(lead_data)
                lead_data['Classifica√ß√£o'] = classification
                await save_lead_to_sheet(lead_data)
                await update.message.reply_text("Pronto! Suas informa√ß√µes foram registradas com sucesso. Entraremos em contato em breve.")

            except json.JSONDecodeError:
                logger.error("Erro ao decodificar o JSON extra√≠do da IA.")
                await update.message.reply_text("Tive um problema ao organizar suas informa√ß√µes. Poderia tentar novamente mais tarde?")

            # Limpa a conversa da mem√≥ria
            del active_chats[user_id]

        else:
            # Se a conversa n√£o terminou, apenas envia a resposta da IA para o usu√°rio
            await update.message.reply_text(ai_response_text)

    except Exception as e:
        logger.error(f"Erro durante a conversa: {e}")
        await update.message.reply_text("Desculpe, ocorreu um erro. Vamos tentar reiniciar. Por favor, envie /start novamente.")
        if user_id in active_chats:
            del active_chats[user_id]


def main() -> None:
    """Fun√ß√£o principal que inicia o bot com a nova l√≥gica."""
    token = os.getenv("TELEGRAM_TOKEN")
    if not token:
        logger.error("Erro: Token do Telegram n√£o encontrado!")
        return
        
    application = Application.builder().token(token).build()

    # Adiciona os novos handlers
    application.add_handler(CommandHandler("start", start))
    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_conversation))

    logger.info("Bot din√¢mico iniciado! Pressione Ctrl+C para parar.")
    application.run_polling()


if __name__ == "__main__":
    main()